import time
import sys
import cv2
import numpy as np
import serial
from picamera2 import Picamera2

try:
    import tflite_runtime.interpreter as tflite
except ImportError:
    try:
        import tensorflow.lite as tflite
    except ImportError:
        print("‚ùå Ch∆∞a c√†i th∆∞ vi·ªán AI! Ch·∫°y: pip3 install tensorflow --break-system-packages")
        sys.exit()

# --- 2. C·∫§U H√åNH ---
MODEL_PATH = "traffic_sign_mobilenetv2_quant.tflite" # <--- T√™n file model .tflite c·ªßa bro
LABEL_PATH = "labels.txt" # (N·∫øu c√≥ file nh√£n ri√™ng, kh√¥ng th√¨ d√πng Dict b√™n d∆∞·ªõi)

FRAME_WIDTH = 640  # ƒê·ªÉ 640x480 cho n√©t
FRAME_HEIGHT = 480
CONFIDENCE_THRESHOLD = 0.5 # ƒê·ªô tin c·∫≠y t·ªëi thi·ªÉu (50%)

# ƒê·ªãnh nghƒ©a c√°c l·ªánh UART
CMD_DICT = {
    0: "CMD_CONSTRUCT",
    1: "CMD_LIMIT_40",
    2: "CMD_LIMIT_50",
    3: "CMD_LIMIT_60",
    4: "CMD_LIMIT_80",
    5: "CMD_STOP"
}

CLASS_NAMES = {
    0: "Cong trinh",
    1: "Limit 40",
    2: "Limit 50",
    3: "Limit 60",
    4: "Limit 80",
    5: "Stop"
}

# --- 3. K·∫æT N·ªêI UART ---
try:
    # C·ªïng th∆∞·ªùng l√† /dev/ttyUSB0 ho·∫∑c /dev/ttyAMA0
    ser = serial.Serial('/dev/ttyUSB0', 115200, timeout=1)
    print("‚úÖ UART Connected!")
except:
    print("‚ö†Ô∏è Warning: Kh√¥ng t√¨m th·∫•y c·ªïng UART (Ch·∫°y ch·∫ø ƒë·ªô kh√¥ng g·ª≠i l·ªánh)")
    ser = None

def send_uart(cmd_idx, conf):
    if ser:
        msg = f"{CMD_DICT.get(cmd_idx, 'UNKNOWN')},{int(conf*100)}\n"
        ser.write(msg.encode('utf-8'))
        print(f"üì° G·ª≠i: {msg.strip()}")

# --- 4. LOAD MODEL ---
print(f"üß† Loading Model: {MODEL_PATH}...")
try:
    interpreter = tflite.Interpreter(model_path=MODEL_PATH)
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    # L·∫•y k√≠ch th∆∞·ªõc ƒë·∫ßu v√†o m√† Model y√™u c·∫ßu (th∆∞·ªùng l√† 320x320 ho·∫∑c 224x224)
    input_shape = input_details[0]['shape']
    input_h, input_w = input_shape[1], input_shape[2]
    print(f"‚ÑπÔ∏è Model input size: {input_w}x{input_h}")
    
except Exception as e:
    print(f"‚ùå L·ªói Load Model: {e}")
    sys.exit()

# --- 5. H√ÄM X·ª¨ L√ù ·∫¢NH & NH·∫¨N DI·ªÜN ---
def detect_objects(frame):
    # 1. Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc Model y√™u c·∫ßu
    img_resized = cv2.resize(frame, (input_w, input_h))
    
    # 2. Chu·∫©n b·ªã ·∫£nh ƒë·∫ßu v√†o (Th∆∞·ªùng Model train b·∫±ng ·∫£nh RGB)
    # V√¨ Picamera2 tr·∫£ v·ªÅ RGB r·ªìi n√™n kh√¥ng c·∫ßn convert m√†u ·ªü ƒë√¢y n·ªØa
    input_data = np.expand_dims(img_resized, axis=0)

    # N·∫øu model train d·∫°ng float (0..1) th√¨ chia 255, n·∫øu uint8 (0..255) th√¨ gi·ªØ nguy√™n
    if input_details[0]['dtype'] == np.float32:
        input_data = (np.float32(input_data) - 127.5) / 127.5 # Ho·∫∑c / 255.0 t√πy model bro train
    else:
        input_data = np.uint8(input_data)

    # 3. Ch·∫°y suy lu·∫≠n (Inference)
    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()

    # 4. L·∫•y k·∫øt qu·∫£
    # T√πy lo·∫°i model (Detection hay Classification) m√† output s·∫Ω kh√°c nhau
    # Code d∆∞·ªõi ƒë√¢y gi·∫£ ƒë·ªãnh model Classification (Ra x√°c su·∫•t c·ªßa t·ª´ng l·ªõp)
    output_data = interpreter.get_tensor(output_details[0]['index'])
    
    # L·∫•y class c√≥ ƒëi·ªÉm s·ªë cao nh·∫•t
    predictions = np.squeeze(output_data)
    class_id = np.argmax(predictions)
    confidence = predictions[class_id]
    
    # N·∫øu output model ch∆∞a ph·∫£i d·∫°ng 0-1 m√† l√† raw score, c√≥ th·ªÉ c·∫ßn softmax (t√πy model)
    if confidence > 1.0: confidence = confidence / 255.0 

    return class_id, confidence

# --- 6. MAIN LOOP ---
def main():
    print("üì∑ Kh·ªüi t·∫°o Camera...")
    picam2 = Picamera2()
    # C·∫•u h√¨nh camera gi·ªëng h·ªát l√∫c test OK
    config = picam2.create_preview_configuration(main={"format": 'RGB888', "size": (FRAME_WIDTH, FRAME_HEIGHT)})
    picam2.configure(config)
    picam2.start()
    
    # ƒê·ª£i cam ·ªïn ƒë·ªãnh
    time.sleep(2)
    print("üöÄ B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán! (Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng)")

    try:
        while True:
            # L·∫•y ·∫£nh t·ª´ camera
            frame = picam2.capture_array()
            
            # --- NH·∫¨N DI·ªÜN ---
            class_id, confidence = detect_objects(frame)

            # --- X·ª¨ L√ù K·∫æT QU·∫¢ ---
            label = "Unknown"
            color = (0, 0, 255) # ƒê·ªè m·∫∑c ƒë·ªãnh
            
            if confidence >= CONFIDENCE_THRESHOLD:
                label = f"{CLASS_NAMES.get(class_id, str(class_id))} ({confidence*100:.1f}%)"
                color = (0, 255, 0) # Xanh l√° n·∫øu nh·∫≠n di·ªán t·ªët
                
                # G·ª≠i UART (ch·ªâ g·ª≠i khi ch·∫Øc ch·∫Øn)
                send_uart(class_id, confidence)
            
            # --- HI·ªÇN TH·ªä ---
            # V·∫Ω l√™n h√¨nh (D√πng copy ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng lu·ªìng ·∫£nh g·ªëc)
            display_frame = frame.copy()
            
            # V√¨ OpenCV hi·ªÉn th·ªã h·ªá m√†u BGR, m√† ·∫£nh l√† RGB
            # N·∫øu bro th·∫•y hi·ªÉn th·ªã tr√™n m√†n h√¨nh b·ªã sai m√†u th√¨ uncomment d√≤ng d∆∞·ªõi:
            display_frame = cv2.cvtColor(display_frame, cv2.COLOR_RGB2BGR) 
            
            cv2.putText(display_frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            cv2.imshow("ADAS System", display_frame)

            if cv2.waitKey(1) == ord('q'):
                break

    except KeyboardInterrupt:
        print("\nüõë D·ª´ng ch∆∞∆°ng tr√¨nh...")
    finally:
        picam2.stop()
        cv2.destroyAllWindows()
        if ser: ser.close()

if __name__ == "__main__":
    main()
